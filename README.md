# AI Content Factory - Custom Multi-Agent Orchestrator

> **Implemented adaptive multi-agent orchestration with live data ingestion and cross-run learning memory enabling strategy reuse and performance-driven agent behavior.**

A production-ready content generation system featuring:
- ğŸ¤– **Multi-Agent Orchestration**: Research, Write, Fact-check, and Optimize.
- ğŸŒ **Real-Time Web Research**: Integrated DuckDuckGo search for live accuracy.
- ğŸ“¡ **Live Data Ingestion**: RSS, CSV, PDF, and REST API support.
- ğŸ§  **Recursive Learning**: Memory system that improves strategies over time.
- ğŸ’¾ **Vector Memory**: ChromaDB-powered semantic retrieval
- ğŸ”Œ **Multi-LLM Support**: Gemini (cloud) or Ollama (local)
- ğŸ“Š **Quality Evaluation**: Readability, structure, keyword density scoring

**No LangChain, CrewAI, or AutoGen** - Pure custom orchestration architecture.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CLI Interface                            â”‚
â”‚                 python main.py --topic "..."                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ContentPipeline                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Strategy   â”‚  â”‚    Run      â”‚  â”‚     Performance         â”‚  â”‚
â”‚  â”‚   Memory    â”‚â—„â”€â”¤   History   â”‚â—„â”€â”¤      Tracker            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AgentManager                               â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ LiveData â”‚  â”‚ Research â”‚  â”‚  Writer  â”‚  â”‚FactCheck â”‚  ...   â”‚
â”‚  â”‚  Agent   â”‚â”€â”€â–¶â”‚  Agent   â”‚â”€â”€â–¶â”‚  Agent   â”‚â”€â”€â–¶â”‚  Agent   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â”‚
â”‚       â”‚             â”‚             â”‚             â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Tool Layer                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   LLM   â”‚  â”‚  Vector â”‚  â”‚  Search â”‚  â”‚    Live Data Tools  â”‚ â”‚
â”‚  â”‚ Client  â”‚  â”‚  Store  â”‚  â”‚  Tool   â”‚  â”‚  RSSâ”‚APIâ”‚PDFâ”‚CSV    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Installation

```bash
cd ai_content_factory

# Install dependencies
pip install -r requirements.txt

# For PDF support (optional)
pip install pymupdf
```

### Basic Usage

```bash
# Using Ollama (local, no API limits)
ollama serve  # Start Ollama in another terminal
ollama pull llama3.2

python main.py --topic "AI in Healthcare"
```

### With Gemini API

```bash
export GEMINI_API_KEY="your-api-key"
# Edit config/agent_config.yaml: provider: "gemini"

python main.py --topic "AI in Healthcare"
```

---

## ï¿½ï¸ ATTIC Interactive CLI Mode

**ATTIC** (Adaptive Tool-driven Intelligent Content Orchestrator) provides an OpenCode-style interactive terminal experience.

### Launch ATTIC

```bash
python run_attic.py
```

### ATTIC Start Screen

```
     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     
    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â•šâ•â•  â•šâ•â•   â•šâ•â•      â•šâ•â•   â•šâ•â• â•šâ•â•â•â•â•â•

    Adaptive Tool-driven Intelligent Content Orchestrator

    Ask anythingâ€¦ "summarize AI policy from rss"

attic >
```

### Natural Language Prompts

Just type naturallyâ€”no flags required! ATTIC auto-detects intent and data sources:

```
attic > summarize latest ai chip news
attic > analyze this csv sales.csv
attic > research climate policy from rss
attic > write report from pdf market.pdf
attic > explain quantum computing
```

### Built-in Commands

| Command | Description |
|---------|-------------|
| `help` | Show help information |
| `history` | Show command history |
| `repeat` | Repeat the last command |
| `stats` | Show session statistics |
| `config` | Show current configuration |
| `clear` | Clear the screen |
| `exit` | Exit ATTIC |

### Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `â†‘/â†“` | Navigate command history |
| `Ctrl+C` | Cancel current operation |
| `Ctrl+D` | Exit ATTIC |

### Live Execution View

During pipeline execution, ATTIC shows real-time progress:

```
â•­â”€ ğŸš€ Pipeline Execution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ â— Live Data Agent    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% â”‚
â”‚ â— Research Agent     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% â”‚
â”‚ â— Writer Agent       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  50% â”‚
â”‚ â—‹ Fact Check Agent   â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   0% â”‚
â”‚ â—‹ Optimizer Agent    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   0% â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

---

## ï¿½ğŸ“¡ Live Data Agent Mode

Ingest real external data sources before research begins.

### Supported Sources

| Type | Description | Example |
|------|-------------|---------|
| **RSS** | News feeds, blogs | `--data-source-url "https://news.google.com/rss"` |
| **API** | REST JSON endpoints | `--api-endpoint "https://api.example.com/data"` |
| **PDF** | Documents (local/URL) | `--data-file report.pdf` |
| **CSV** | Datasets | `--data-file sales.csv` |

### Usage Examples

```bash
# RSS Feed
python main.py --topic "Climate Policy" --live-data \
  --data-source-url "https://news.google.com/rss/search?q=climate"

# CSV Dataset
python main.py --topic "Sales Analysis" --live-data \
  --data-file data/sales_2024.csv

# API Endpoint
python main.py --topic "Weather Report" --live-data \
  --api-endpoint "https://api.weather.gov/gridpoints/OKX/35,37/forecast"

# PDF Document
python main.py --topic "Research Summary" --live-data \
  --data-file papers/research.pdf
```

### How It Works

1. **LiveDataAgent** runs first when `--live-data` is enabled
2. Fetches data from all configured sources
3. Normalizes content into documents
4. Stores in ChromaDB vector store
5. **ResearchAgent** retrieves relevant context
6. Pipeline continues with enriched knowledge

---

## ğŸ§  Long-Term Learning Memory

The system learns from each run and improves over time.

### Components

| Component | Purpose | Storage |
|-----------|---------|---------|
| **RunHistoryStore** | Tracks every pipeline execution | SQLite |
| **StrategyMemory** | Remembers successful strategies | SQLite |
| **PerformanceTracker** | Agent metrics and failure patterns | SQLite |

### What Gets Learned

- âœ… Which prompts produce best results
- âœ… Which tools succeed for which topics
- âœ… Optimal agent execution order
- âœ… Topic category patterns
- âœ… Performance trends over time

### View Learning Statistics

```bash
python main.py --show-stats
```

### Disable Learning

```bash
python main.py --topic "Quick Test" --no-learning
```

---

## ğŸ“ Project Structure

```
ai_content_factory/
â”œâ”€â”€ agents/                    # Agent implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_agent.py         # Abstract base agent
â”‚   â”œâ”€â”€ research_agent.py     # Research specialist
â”‚   â”œâ”€â”€ writer_agent.py       # Content writer
â”‚   â”œâ”€â”€ factcheck_agent.py    # Fact checker
â”‚   â”œâ”€â”€ optimizer_agent.py    # Content optimizer
â”‚   â””â”€â”€ live_data_agent.py    # Live data ingestion
â”‚
â”œâ”€â”€ orchestrator/              # Pipeline orchestration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline.py           # Main pipeline
â”‚   â””â”€â”€ agent_manager.py      # Agent execution
â”‚
â”œâ”€â”€ tools/                     # Tool implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_client.py         # Gemini/Ollama clients
â”‚   â”œâ”€â”€ search_tool.py        # Abstract/Mock search
â”‚   â”œâ”€â”€ ddg_search.py         # Real DuckDuckGo search
â”‚   â”œâ”€â”€ vector_store.py       # ChromaDB wrapper
â”‚   â”œâ”€â”€ evaluator.py          # Content scoring
â”‚   â”œâ”€â”€ live_data_tools.py    # Unified data interface
â”‚   â”œâ”€â”€ rss_reader.py         # RSS/Atom parser
â”‚   â”œâ”€â”€ api_client.py         # REST API client
â”‚   â”œâ”€â”€ pdf_loader.py         # PDF extraction
â”‚   â””â”€â”€ csv_loader.py         # CSV loading
â”‚
â”œâ”€â”€ memory/                    # Learning system
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ run_history_store.py  # Execution history
â”‚   â”œâ”€â”€ strategy_memory.py    # Strategy learning
â”‚   â””â”€â”€ performance_tracker.py # Metrics tracking
â”‚
â”œâ”€â”€ attic_cli/                 # ATTIC Interactive CLI
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ banner.py             # ASCII art banner
â”‚   â”œâ”€â”€ command_parser.py     # Natural language parsing
â”‚   â”œâ”€â”€ rich_layout.py        # UI components
â”‚   â”œâ”€â”€ session_state.py      # Session management
â”‚   â””â”€â”€ interactive_shell.py  # Main shell
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ agent_config.yaml     # Configuration
â”‚
â”œâ”€â”€ data/                      # SQLite databases
â”‚   â”œâ”€â”€ run_history.db
â”‚   â”œâ”€â”€ strategy_memory.db
â”‚   â””â”€â”€ performance.db
â”‚
â”œâ”€â”€ runs/                      # Run output logs
â”‚   â””â”€â”€ run_<timestamp>/
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ strategy_used.json
â”‚       â”œâ”€â”€ evaluation.json
â”‚       â”œâ”€â”€ agent_outputs/
â”‚       â””â”€â”€ live_data_raw/
â”‚
â”œâ”€â”€ main.py                    # Flag-based CLI
â”œâ”€â”€ run_attic.py               # ATTIC interactive CLI
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

Edit `config/agent_config.yaml`:

```yaml
# LLM Provider
llm:
  provider: "ollama"  # or "gemini"
  model: "llama3.2"
  temperature: 0.7
  max_tokens: 2000

# Feature Flags
live_data_enabled: false      # Default for all runs
learning_memory_enabled: true # Enable learning

# Tool Permissions
tool_permissions:
  live_data_agent:
    - rss
    - api
    - pdf
    - csv
```

---

## ğŸ“Š CLI Reference

```
usage: main.py [-h] --topic TOPIC [--live-data] [--data-source-url URL]
               [--data-file FILE] [--api-endpoint URL] [--no-learning]
               [--output FILE] [--verbose] [--config PATH] [--show-stats]

Options:
  --topic TOPIC           Topic to generate content about (required)
  --live-data             Enable live data ingestion
  --data-source-url URL   URL for live data (RSS, API, PDF)
  --data-file FILE        Local file path (CSV, PDF)
  --api-endpoint URL      REST API endpoint
  --no-learning           Disable learning memory
  --output, -o FILE       Save output to file
  --verbose, -v           Enable debug logging
  --config PATH           Custom config file path
  --show-stats            Show learning statistics
```

---

## ğŸ”§ Development

### Adding New Agents

1. Create `agents/new_agent.py` extending `BaseAgent`
2. Implement `execute()` method
3. Register in `pipeline.py`

### Adding New Data Sources

1. Create `tools/new_loader.py`
2. Add to `LiveDataTools` class
3. Update `DataSourceType` enum

---

## ğŸ“ˆ Performance

Typical execution times (with Ollama llama3.2):

| Mode | Agents | Time |
|------|--------|------|
| Standard | 4 | ~2-3 min |
| Live Data | 5 | ~3-4 min |

Quality scores typically range 75-95 depending on topic complexity.

---

## ğŸ“ License

MIT License - See LICENSE file

---

## ğŸ™ Acknowledgments

Built with:
- [Ollama](https://ollama.ai/) - Local LLM inference
- [Google Gemini](https://ai.google.dev/) - Cloud LLM API
- [ChromaDB](https://www.trychroma.com/) - Vector database
- [Rich](https://rich.readthedocs.io/) - Terminal UI
